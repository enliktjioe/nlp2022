{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parliamentary-photograph",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- https://realpython.com/sentiment-analysis-python/\n",
    "- https://github.com/realpython/materials/blob/master/nlp-sentiment-analysis/sentiment_analyzer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-overhead",
   "metadata": {},
   "source": [
    "# Let's Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-coating",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weird-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " Dave,\n",
       " watched,\n",
       " as,\n",
       " the,\n",
       " forest,\n",
       " burned,\n",
       " up,\n",
       " on,\n",
       " the,\n",
       " hill,\n",
       " ,,\n",
       " ,\n",
       " only,\n",
       " a,\n",
       " few,\n",
       " miles,\n",
       " from,\n",
       " his,\n",
       " house,\n",
       " .,\n",
       " The,\n",
       " car,\n",
       " had,\n",
       " ,\n",
       " been,\n",
       " hastily,\n",
       " packed,\n",
       " and,\n",
       " Marta,\n",
       " was,\n",
       " inside,\n",
       " trying,\n",
       " to,\n",
       " round,\n",
       " ,\n",
       " up,\n",
       " the,\n",
       " last,\n",
       " of,\n",
       " the,\n",
       " pets,\n",
       " .,\n",
       " \",\n",
       " Where,\n",
       " could,\n",
       " she,\n",
       " be,\n",
       " ?,\n",
       " \",\n",
       " he,\n",
       " wondered,\n",
       " ,\n",
       " as,\n",
       " he,\n",
       " continued,\n",
       " to,\n",
       " wait,\n",
       " for,\n",
       " Marta,\n",
       " to,\n",
       " appear,\n",
       " with,\n",
       " the,\n",
       " pets,\n",
       " .,\n",
       " ]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "token_list = [token for token in doc]\n",
    "token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-programming",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "graphic-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " Dave,\n",
       " watched,\n",
       " forest,\n",
       " burned,\n",
       " hill,\n",
       " ,,\n",
       " ,\n",
       " miles,\n",
       " house,\n",
       " .,\n",
       " car,\n",
       " ,\n",
       " hastily,\n",
       " packed,\n",
       " Marta,\n",
       " inside,\n",
       " trying,\n",
       " round,\n",
       " ,\n",
       " pets,\n",
       " .,\n",
       " \",\n",
       " ?,\n",
       " \",\n",
       " wondered,\n",
       " ,\n",
       " continued,\n",
       " wait,\n",
       " Marta,\n",
       " appear,\n",
       " pets,\n",
       " .,\n",
       " ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-marking",
   "metadata": {},
   "source": [
    "## Normalizing Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-business",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "- lemmatization is generally more powerful than stemming, it’s the only normalization strategy offered by spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "asian-mirror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Token: \\n, lemma: \\n',\n",
       " 'Token: Dave, lemma: Dave',\n",
       " 'Token: watched, lemma: watch',\n",
       " 'Token: forest, lemma: forest',\n",
       " 'Token: burned, lemma: burn',\n",
       " 'Token: hill, lemma: hill',\n",
       " 'Token: ,, lemma: ,',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: miles, lemma: mile',\n",
       " 'Token: house, lemma: house',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: car, lemma: car',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: hastily, lemma: hastily',\n",
       " 'Token: packed, lemma: pack',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: inside, lemma: inside',\n",
       " 'Token: trying, lemma: try',\n",
       " 'Token: round, lemma: round',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: ?, lemma: ?',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: wondered, lemma: wonder',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: continued, lemma: continue',\n",
       " 'Token: wait, lemma: wait',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: appear, lemma: appear',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \\n, lemma: \\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [f\"Token: {token}, lemma: {token.lemma_}\" for token in filtered_tokens]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-topic",
   "metadata": {},
   "source": [
    "## Vectorizing Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "durable-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8371646 ,  1.4529226 , -1.6147211 ,  0.678362  , -0.6594443 ,\n",
       "        1.6417935 ,  0.5796405 ,  2.3021278 , -0.13260496,  0.5750932 ,\n",
       "        1.5654886 , -0.6938864 , -0.59607106, -1.5377437 ,  1.9425622 ,\n",
       "       -2.4552505 ,  1.2321601 ,  1.0434952 , -1.5102385 , -0.5787632 ,\n",
       "        0.12055647,  3.6501784 ,  2.6160972 , -0.5710199 , -1.5221789 ,\n",
       "        0.00629176,  0.22760668, -1.922073  , -1.6252862 , -4.226225  ,\n",
       "       -3.495663  , -3.312053  ,  0.81387717, -0.00677544, -0.11603224,\n",
       "        1.4620426 ,  3.0751472 ,  0.35958546, -0.22527039, -2.743926  ,\n",
       "        1.269633  ,  4.606786  ,  0.34034157, -2.1272311 ,  1.2619178 ,\n",
       "       -4.209798  ,  5.452852  ,  1.6940253 , -2.5972986 ,  0.95049495,\n",
       "       -1.910578  , -2.374927  , -1.4227567 , -2.2528825 , -1.799806  ,\n",
       "        1.607501  ,  2.9914255 ,  2.8065152 , -1.2510269 , -0.54964066,\n",
       "       -0.49980402, -1.3882618 , -0.470479  , -2.9670253 ,  1.7884955 ,\n",
       "        4.5282774 , -1.2602427 , -0.14885521,  1.0419178 , -0.08892632,\n",
       "       -1.138275  ,  2.242618  ,  1.5077229 , -1.5030195 ,  2.528098  ,\n",
       "       -1.6761329 ,  0.16694719,  2.123961  ,  0.02546412,  0.38754445,\n",
       "        0.8911977 , -0.07678384, -2.0690763 , -1.1211847 ,  1.4821006 ,\n",
       "        1.1989193 ,  2.1933236 ,  0.5296372 ,  3.0646474 , -1.7223308 ,\n",
       "       -1.3634219 , -0.47471118, -1.7648507 ,  3.565178  , -2.394205  ,\n",
       "       -1.3800384 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens[1].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-rochester",
   "metadata": {},
   "source": [
    "## Using Machine Learning Classifiers to Predict Sentiment\n",
    "\n",
    "tools:\n",
    "- TensorFlow\n",
    "- PyTorch\n",
    "- scikit-learn\n",
    "\n",
    "Luckily, spaCy provides a fairly straightforward built-in text classifier that you’ll learn about a little later. First, however, it’s important to understand the general workflow for any sort of classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-filing",
   "metadata": {},
   "source": [
    "### How Classification Works\n",
    "\n",
    "- Split your data into training and evaluation sets.\n",
    "- Select a model architecture.\n",
    "- Use training data to train your model.\n",
    "- Use test data to evaluate the performance of your model.\n",
    "- Use your trained model on new data to generate predictions, which in this case will be a number between -1.0 and 1.0.\n",
    "\n",
    "machine learning practitioners often split their datasets into three sets:\n",
    "\n",
    "- Training\n",
    "- Validation\n",
    "- Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-matthew",
   "metadata": {},
   "source": [
    "## Building Your Own NLP Sentiment Analyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-orleans",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dietary-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import pandas as pd\n",
    "\n",
    "TEST_REVIEW = \"\"\"\n",
    "Transcendently beautiful in moments outside the office, it seems almost\n",
    "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
    "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
    "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
    "doesn't matter. (The worst is sort of tedious - like Office Space with less\n",
    "humor.)\n",
    "\"\"\"\n",
    "\n",
    "eval_list = []\n",
    "\n",
    "def train_model(\n",
    "    training_data: list, test_data: list, iterations: int = 20\n",
    ") -> None:\n",
    "    # Build pipeline\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")\n",
    "\n",
    "    # Train only textcat\n",
    "    training_excluded_pipes = [\n",
    "        pipe for pipe in nlp.pipe_names if pipe != \"textcat\"\n",
    "    ]\n",
    "    with nlp.disable_pipes(training_excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        # Training loop\n",
    "        print(\"Beginning training\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
    "        batch_sizes = compounding(\n",
    "            4.0, 32.0, 1.001\n",
    "        )  # A generator that yields infinite series of input numbers\n",
    "        for i in range(iterations):\n",
    "            print(f\"Training iteration {i}\")\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, labels = zip(*batch)\n",
    "                nlp.update(text, labels, drop=0.2, sgd=optimizer, losses=loss)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                evaluation_results = evaluate_model(\n",
    "                    tokenizer=nlp.tokenizer,\n",
    "                    textcat=textcat,\n",
    "                    test_data=test_data,\n",
    "                )\n",
    "                print(\n",
    "                    f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
    "                    f\"\\t{evaluation_results['recall']}\"\n",
    "                    f\"\\t{evaluation_results['f-score']}\"\n",
    "                )\n",
    "\n",
    "    # Save model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")\n",
    "\n",
    "\n",
    "def evaluate_model(tokenizer, textcat, test_data: list) -> dict:\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (tokenizer(review) for review in reviews)\n",
    "    true_positives = 0\n",
    "    false_positives = 1e-8  # Can't be 0 because of presence in denominator\n",
    "    true_negatives = 0\n",
    "    false_negatives = 1e-8\n",
    "    for i, review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i][\"cats\"]\n",
    "        for predicted_label, score in review.cats.items():\n",
    "            # Every cats dictionary includes both labels, you can get all\n",
    "            # the info you need with just the pos label\n",
    "            if predicted_label == \"neg\":\n",
    "                continue\n",
    "            if score >= 0.5 and true_label[\"pos\"]:\n",
    "                true_positives += 1\n",
    "            elif score >= 0.5 and true_label[\"neg\"]:\n",
    "                false_positives += 1\n",
    "            elif score < 0.5 and true_label[\"neg\"]:\n",
    "                true_negatives += 1\n",
    "            elif score < 0.5 and true_label[\"pos\"]:\n",
    "                false_negatives += 1\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}\n",
    "\n",
    "\n",
    "def test_model(input_data: str = TEST_REVIEW):\n",
    "    #  Load saved trained model\n",
    "    loaded_model = spacy.load(\"model_artifacts\")\n",
    "    # Generate prediction\n",
    "    parsed_text = loaded_model(input_data)\n",
    "    # Determine prediction to return\n",
    "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
    "        prediction = \"Positive\"\n",
    "        score = parsed_text.cats[\"pos\"]\n",
    "    else:\n",
    "        prediction = \"Negative\"\n",
    "        score = parsed_text.cats[\"neg\"]\n",
    "    print(\n",
    "        f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
    "        f\"\\tScore: {score}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_training_data(\n",
    "    data_directory: str = \"dataset/aclImdb/train\", split: float = 0.8, limit: int = 0\n",
    ") -> tuple:\n",
    "    # Load from files\n",
    "    reviews = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        labeled_directory = f\"{data_directory}/{label}\"\n",
    "        for review in os.listdir(labeled_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                with open(f\"{labeled_directory}/{review}\", encoding=\"utf8\") as f:\n",
    "                    text = f.read()\n",
    "                    text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                    if text.strip():\n",
    "                        spacy_label = {\n",
    "                            \"cats\": {\n",
    "                                \"pos\": \"pos\" == label,\n",
    "                                \"neg\": \"neg\" == label,\n",
    "                            }\n",
    "                        }\n",
    "                        reviews.append((text, spacy_label))\n",
    "    random.shuffle(reviews)\n",
    "\n",
    "    if limit:\n",
    "        reviews = reviews[:limit]\n",
    "    split = int(len(reviews) * split)\n",
    "    return reviews[:split], reviews[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "operational-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Beginning training\n",
      "Loss\tPrecision\tRecall\tF-score\n",
      "Training iteration 0\n",
      "0.1594244632869959\t0.5999999988\t0.9999999966666667\t0.749999998125\n",
      "Training iteration 1\n",
      "0.14076493866741657\t0.5999999988\t0.9999999966666667\t0.749999998125\n",
      "Training iteration 2\n",
      "0.10239794291555882\t0.0\t0.0\t0\n",
      "Training iteration 3\n",
      "0.06422404432669282\t0.6666666644444444\t0.6666666644444444\t0.6666666644444444\n",
      "Training iteration 4\n",
      "0.031850377563387156\t0.6666666644444444\t0.6666666644444444\t0.6666666644444444\n",
      "Training iteration 5\n",
      "0.016199110366869718\t0.6666666644444444\t0.6666666644444444\t0.6666666644444444\n",
      "Training iteration 6\n",
      "0.024295946509937494\t0.7499999981250001\t0.9999999966666667\t0.8571428546938776\n",
      "Training iteration 7\n",
      "0.006184204679811955\t0.0\t0.0\t0\n",
      "Training iteration 8\n",
      "0.012749479505146155\t0.0\t0.0\t0\n",
      "Training iteration 9\n",
      "0.00023829929494922908\t0.4999999975\t0.3333333322222222\t0.3999999984\n",
      "Training iteration 10\n",
      "0.0051634207387536435\t0.6666666644444444\t0.6666666644444444\t0.6666666644444444\n",
      "Training iteration 11\n",
      "0.002886697754092893\t0.0\t0.0\t0\n",
      "Training iteration 12\n",
      "0.0007732194131335746\t0.4999999975\t0.3333333322222222\t0.3999999984\n",
      "Training iteration 13\n",
      "0.0001883989731368274\t0.6666666644444444\t0.6666666644444444\t0.6666666644444444\n",
      "Training iteration 14\n",
      "0.0024951807798245795\t0.4999999975\t0.3333333322222222\t0.3999999984\n",
      "Training iteration 15\n",
      "1.0674364204987796e-05\t0.9999999900000002\t0.3333333322222222\t0.4999999975\n",
      "Training iteration 16\n",
      "0.0034222000903696426\t0.0\t0.0\t0\n",
      "Training iteration 17\n",
      "0.001453071489663671\t0.4999999975\t0.3333333322222222\t0.3999999984\n",
      "Training iteration 18\n",
      "0.003503882836113803\t0.7499999981250001\t0.9999999966666667\t0.8571428546938776\n",
      "Training iteration 19\n",
      "1.596939402048747e-05\t0.7499999981250001\t0.9999999966666667\t0.8571428546938776\n",
      "Testing model\n",
      "Review text: \n",
      "Transcendently beautiful in moments outside the office, it seems almost\n",
      "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
      "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
      "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
      "doesn't matter. (The worst is sort of tedious - like Office Space with less\n",
      "humor.)\n",
      "\n",
      "Predicted sentiment: Negative\tScore: 0.7364301681518555\n"
     ]
    }
   ],
   "source": [
    "train, test = load_training_data(limit=25)\n",
    "print(\"Training model\")\n",
    "train_model(train, test)\n",
    "df = pd.DataFrame(eval_list)\n",
    "pd.DataFrame.plot(df)\n",
    "print(\"Testing model\")\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-machinery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
